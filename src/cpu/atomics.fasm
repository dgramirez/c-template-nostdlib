section '.bss' writeable
	atomic_store128_lock dq 0
	atomic_cas128_lock dq 0

section '.text' executable align 16
match =LINUX, PLATFORM {
	; void atomic_store(void *ptr, isz val)
	public atomic_store
	atomic_store:
		use64

		mov [rdi], rsi
		sfence
		ret

	; void atomic_store32(void *ptr, isz val)
	public atomic_store32
	atomic_store32:
		use32

		mov [edi], esi
		sfence
		ret

	; void atomic_store128(void *ptr, void *val)
	public atomic_store128
	atomic_store128:
		use64

		pushq [rsi]
		pushq [rsi+8]

		; SPINLOCK
		.spinlock_wait_store128:
		lea r8, [atomic_store128_lock]
		xor rax, rax
		mov rcx, 1
		lock cmpxchg [r8], rcx
		jnz .spinlock_wait_store128

		; CRITICAL SECTION
		popq [rdi+8]
		popq [rdi]

		; RELEASE LOCK
		mov qword [r8], 0
		ret

	; isz atomic_load(void *ptr)
	public atomic_load
	atomic_load:
		use64

		lfence
		mov rax, [rdi]
		ret

	; isz atomic_load32(void *ptr)
	public atomic_load32
	atomic_load32:
		use32

		lfence
		mov eax, [edi]
		ret

	; isz atomic_cas(void *ptr, isz old_val, isz new_val)
	public atomic_cas
	atomic_cas:
		use64

		; Compare and Swap
		mov rax, rsi
		lock cmpxchg [rdi], rdx
		ret

	; isz atomic_cas128(void *ptr, void *old_val, void *new_val)
	public atomic_cas128
	atomic_cas128:
		use64

		pushq [rdx+8]
		pushq [rdx]

		; SPINLOCK
		.spinlock_wait_cas128:
		lea r8, [atomic_cas128_lock]
		xor rax, rax
		mov rcx, 1
		lock cmpxchg [r8], rcx
		jnz .spinlock_wait_cas128

		; CRITICAL SECTION
		mov rax, [rsi]
		popq rcx
		cmpxchg [rdi], rcx
		jnz .cas128_fail

		mov rax, [rsi+8]
		pop rcx
		cmpxchg [rdi+8], rcx
		jnz .cas128_fail

		; RELEASE LOCK
		mov qword [r8], 0
		mov rax, 1
		ret

		.cas128_fail:
		mov qword [r8], 0
		mov rax, 0
		ret

	; isz atomic_swap(void *ptr, isz val)
	public atomic_swap
	atomic_swap:
		use64

		; Swap
		mov rax, rsi
		lock xchg [rdi], rax
		ret

	; void atomic_inc(void *ptr)
	public atomic_inc
	atomic_inc:
		use64

		; Add and Fetch
		lock add [rdi], WORD 1
		ret

	; void atomic_dec(void *ptr)
	public atomic_dec
	atomic_dec:
		use64

		; Add and Fetch
		lock add [rdi], WORD -1
		ret

	; void atomic_add(void *ptr, void *val)
	public atomic_add
	atomic_add:
		use64

		; Add and Fetch
		lock add [rdi], rsi
		ret

	; void atomic_bit_set(void *ptr, void *val)
	public atomic_bit_set
	atomic_bit_set:
		use64

		; Or and Fetch
		lock or [rdi], rsi
		ret

	; void atomic_bit_clear(void *ptr, void *val)
	public atomic_bit_clear
	atomic_bit_clear:
		use64

		; And and Fetch
		not rsi
		lock and [rdi], rsi
		ret

	; void load_barrier()
	public load_barrier
	load_barrier:
		lfence
		ret

	; void store_barrier()
	public store_barrier
	store_barrier:
		sfence
		ret

	; void cpu_barrier()
	public cpu_barrier
	cpu_barrier:
		mfence
		ret

	; void cpu_relax()
	public cpu_relax
	cpu_relax:
		pause
		ret
}

match =WIN64, PLATFORM {
	; void atomic_store(void *ptr, isz val)
	public atomic_store
	atomic_store:
		use64

		mov [rcx], rdx
		sfence
		ret

	; isz atomic_load(void *ptr)
	public atomic_load
	atomic_load:
		use64

		lfence
		mov rax, [rcx]
		ret

	; isz atomic_xadd(void *ptr, isz val)
	public atomic_xadd
	atomic_xadd:
		use64

		; Fetch And Add
		mov rax, rdx
		lock xadd [rcx], rax
		ret

	; isz atomic_xmpxchg(void *ptr, isz old_val, isz new_val)
	public atomic_cas
	atomic_cas:
		use64

		; Compare and Swap
		mov rax, rdx
		lock cmpxchg [rcx], r8
		ret

	; isz atomic_swap(void *ptr, isz val)
	public atomic_swap
	atomic_swap:
		use64

		; Swap
		mov rax, rdx
		lock xchg [rcx], rax
		ret

	; void atomic_inc(void *ptr)
	public atomic_inc
	atomic_inc:
		use64

		; Add and Fetch
		lock add [rcx], WORD 1
		ret

	; void atomic_dec(void *ptr)
	public atomic_dec
	atomic_dec:
		use64

		; Add and Fetch
		lock add [rcx], WORD -1
		ret

	; void atomic_add(void *ptr, void *val)
	public atomic_add
	atomic_add:
		use64

		; Add and Fetch
		lock add [rcx], rdx
		ret

	; void atomic_bit_set(void *ptr, void *val)
	public atomic_bit_set
	atomic_bit_set:
		use64

		; Or and Fetch
		lock or [rcx], rdx
		ret

	; void atomic_bit_clear(void *ptr, void *val)
	public atomic_bit_clear
	atomic_bit_clear:
		use64

		; And and Fetch
		not rdx
		lock and [rcx], rdx
		ret

	; void load_barrier()
	public load_barrier
	load_barrier:
		lfence
		ret

	; void store_barrier()
	public store_barrier
	store_barrier:
		sfence
		ret

	; void cpu_barrier()
	public cpu_barrier
	cpu_barrier:
		mfence
		ret

	; void cpu_relax()
	public cpu_relax
	cpu_relax:
		pause
		ret
}

match =WIN32, PLATFORM {
	; void __fastcall atomic_store(void *ptr, isz val)
	public atomic_store as '@atomic_store@8'
	atomic_store:
		use32

		mov [ecx], edx
		sfence
		ret

	; isz __fastcall atomic_load(void *ptr)
	public atomic_load as '@atomic_load@4'
	atomic_load:
		use32

		lfence
		mov eax, [ecx]
		ret

	; isz __fastcall atomic_add(void *ptr, isz val)
	public atomic_xadd as '@atomic_xadd@8'
	atomic_xadd:
		use32

		; Fetch And Add
		mov eax, edx
		lock xadd [ecx], eax
		ret

	; isz __fastcall atomic_xmpxchg(void *ptr, isz old_val, isz new_val)
	public atomic_cas as '@atomic_cas@12'
	atomic_cas:
		use32

		; Compare and Swap
		push ebx
		push esi

		mov esi, [esp+(1+2)*4]
		mov ebx, esi

		mov eax, edx
		lock cmpxchg [ecx], ebx

		pop esi
		pop ebx

		ret

	; isz __fastcall atomic_swap(void *ptr, isz val)
	public atomic_swap as '@atomic_swap@8'
	atomic_swap:
		use32

		; Swap
		mov eax, edx
		lock xchg [ecx], eax
		ret

	; void __fastcall atomic_inc(void *ptr)
	public atomic_inc as '@atomic_inc@4'
	atomic_inc:
		use32

		; Add and Fetch
		lock add [ecx], WORD 1
		ret

	; void __fastcall atomic_dec(void *ptr)
	public atomic_dec as '@atomic_dec@4'
	atomic_dec:
		use32

		; Add and Fetch
		lock add [ecx], WORD -1
		ret

	; void __fastcall atomic_add(void *ptr, void *val)
	public atomic_add as '@atomic_add@8'
	atomic_add:
		use32

		; Add and Fetch
		lock add [ecx], edx
		ret

	; void __fastcall atomic_bit_set(void *ptr, void *val)
	public atomic_bit_set as '@atomic_bit_set@8'
	atomic_bit_set:
		use32

		; Or and Fetch
		lock or [ecx], edx
		ret

	; void __fastcall atomic_bit_clear(void *ptr, void *val)
	public atomic_bit_clear as '@atomic_bit_clear@8'
	atomic_bit_clear:
		use32

		; And and Fetch
		not edx
		lock and [ecx], edx
		ret

	; void load_barrier()
	public load_barrier as '@load_barrier@0'
	load_barrier:
		lfence
		ret

	; void store_barrier()
	public store_barrier as '@store_barrier@0'
	store_barrier:
		sfence
		ret

	; void cpu_barrier()
	public cpu_barrier as '@cpu_barrier@0'
	cpu_barrier:
		mfence
		ret

	; void cpu_relax()
	public cpu_relax as '@cpu_relax@0'
	cpu_relax:
		pause
		ret
}

